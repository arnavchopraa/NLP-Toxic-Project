{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "!pip install benepar\n",
    "import benepar\n",
    "\n",
    "benepar.download('benepar_en3')\n",
    "\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "from collections import Counter\n",
    "from nltk import Tree"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add benepar to the pipeline\n",
    "\n",
    "nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ],
   "id": "37b2481d2d6c8e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = \"bloom\"     # \"mistral\" / \"bloom\" / \"llama\"\n",
    "\n",
    "toxic_prompts = [json.loads(x)[\"prompt\"] for x in open(f\"results/{model}/most_toxic.jsonl\").readlines()]\n",
    "\n",
    "nontoxic_prompts = [json.loads(x)[\"prompt\"] for x in open(f\"results/{model}/least_toxic.jsonl\").readlines()]\n",
    "\n",
    "\n",
    "def extract_constituency_trees(sentences):\n",
    "    trees = []\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "        for sent in doc.sents:\n",
    "            tree = Tree.fromstring(sent._.parse_string)\n",
    "            trees.append(tree)\n",
    "    return trees\n",
    "\n",
    "toxic_trees = extract_constituency_trees(toxic_prompts)\n",
    "nontoxic_trees = extract_constituency_trees(nontoxic_prompts)"
   ],
   "id": "c5090de2fa139111",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_non_leaf_phrases(tree):\n",
    "    \"\"\" Recursively extract non-leaf phrase types from a constituency tree. \"\"\"\n",
    "    phrases = []\n",
    "    if isinstance(tree, Tree) and tree.height() > 2:  # Exclude leaf nodes\n",
    "        phrase_structure = (tree.label(), tuple(extract_non_leaf_phrases(subtree) for subtree in tree if isinstance(subtree, Tree)))\n",
    "        phrases.append(phrase_structure)\n",
    "        for subtree in tree:\n",
    "            phrases.extend(extract_non_leaf_phrases(subtree))\n",
    "    return phrases\n",
    "\n",
    "# Extract and count non-leaf phrase type subtrees\n",
    "def extract_and_count_non_leaf_subtrees(trees):\n",
    "    subtree_counter = Counter()\n",
    "    for tree in trees:\n",
    "        non_leaf_subtrees = extract_non_leaf_phrases(tree)\n",
    "        non_leaf_subtree_strings = [str(subtree) for subtree in non_leaf_subtrees]\n",
    "        subtree_counter.update(non_leaf_subtree_strings)\n",
    "    return subtree_counter\n",
    "\n",
    "non_leaf_subtree_patterns = extract_and_count_non_leaf_subtrees(toxic_trees)\n",
    "# non_leaf_subtree_patterns = extract_and_count_non_leaf_subtrees(nontoxic_trees)\n",
    "\n",
    "# Print the most common non-leaf subtrees by phrase types, ordered by count\n",
    "print(\"Most common non-leaf subtrees by phrase types:\")\n",
    "for subtree, count in non_leaf_subtree_patterns.most_common(5):\n",
    "    print(f\"{subtree}: {count}\")\n"
   ],
   "id": "468357bc47b21132",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
